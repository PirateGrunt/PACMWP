---
title: Thin Data
output: 
  revealjs::revealjs_presentation:
    theme: black
    transition: none
    center: false
---

```{r include = FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)

knitr::opts_chunk$set(
    echo = FALSE
  , warning = FALSE
)
```

# What is thin data? 

## What is thin data

Thin data is everything that big data isn't.

Thin data is:

- Collected rarely (quarterly, annually)
- Short (fewer than 50 observations)
- Possibly wide (overspecified)

Reasons for thin data in capital modeling

- Limited number of entities
- May be limited to public financials
- Entitites would want to limit availability of details about capital stresses
- 

##

##

##

# Mitigation

## Mitigation

```{r }
tribble(
    ~Method, ~Description
  , 'Case control study', 'Identify exemplary cases and work backwords'
  , 'Bootstrap', 'Sample with replacement'
  , 'Bayes', 'Alter a distribution based on data and prior judgment'
  , 'Penalized regression', 'Restrict the number and/or influence of parameters') %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Case control study

## CCS
  Select controls based on characteristics of the observed cases
  Recognizes that we can't conduct a controlled experiment by splitting a population
  Used widely in epidemiology, but has also been used in political science, studies of personal bankruptcy
  Example: Insurance company insolvencies in a limited time frame; we might select controls of similar size and focus
  
  *Pros
    Allows limited causal inferences from a relatively small dataset
    Full understanding of the limitations of the control group
  *Cons
    Bias inherent in control selection
    Does not allow inferences about population incidence

# Bootstrap

## Bootstrap

Bootstrap methods use resampling from an observed dataset to draw inferences about the sampling dataset
 
Bootstrap methods do assume that the sampling dataset is a good representation of the true underlying process

Allow development of confidence intervals for the sampling dataset

Bootstrap-type methods can also be used to validate models
  Is the model robust to a different sample from the observed dataset?
  

# Bayes

## Bayes

Mama weer all Bayezee now

# Penalized regression

*Standard regression methods can show significance for small effects in a small sample
*Penalized regression allows practitioner to set a bar for inclusion of parameters and their associated effects
*Can be used to prevent overfitting to a small dataset


## Penalized regresssion

What is the L2 norm

## Lasso - Coefficients penalized linearly
  Useful when practitioner wants to simplify model to effects of a certain size
## Ridge - Coefficients asymptotically approach zero
  Useful when goal is to limit magnitude of effects, but maintain all the predictors

## Elastic Net - Weighted combination of lasso and ridge

# Conclusion
